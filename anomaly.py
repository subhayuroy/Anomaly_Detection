# -*- coding: utf-8 -*-
"""Anomaly.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d6BALnQoTL9sA60bmlXi4dRHOWKV8Vae

#Anomaly Detection

Anomaly detection can be treated as a statistical task as an outlier analysis. But if we develop a machine learning model, it can be automated and as usual, can save a lot of time.

*There are so many use cases of anomaly detection. Credit card fraud detection, detection of faulty machines, or hardware systems detection based on their anomalous features, disease detection based on medical records are some good examples. There are many more use cases.*

***And the use of anomaly detection will only grow.***

Importing the necessary packages
"""

import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_excel('ex8data1.xlsx', sheet_name='X', header=None)

df.head()

"""Let’s plot column 0 against column 1."""

plt.figure()
plt.scatter(df[0], df[1])
plt.show()

m = len(df)

"""Calculate the mean for each feature. Here we have only two features: 0 and 1."""

s = np.sum(df, axis=0)
mu = s/m
mu

"""Let’s calculate the variance:"""

vr = np.sum((df - mu)**2, axis=0)
variance = vr/m
variance

"""Now make it diagonal shaped."""

var_dia = np.diag(variance)
var_dia

"""Calculate the probability:"""

k = len(mu)
X = df - mu
p = 1/((2*np.pi)**(k/2)*(np.linalg.det(var_dia)**0.5))* np.exp(-0.5* np.sum(X @ np.linalg.pinv(var_dia) * X,axis=1))
p

"""The next step is to find out the threshold probability. If the probability is lower than the threshold probability, the example data is anomalous data. But we need to find out that threshold for our particular case.

For this step, we use cross-validation data and also the labels. In this dataset, we have the cross-validation data and also the labels in separate sheets.
"""

cvx = pd.read_excel('ex8data1.xlsx', sheet_name='Xval', header=None)

cvx.head()

"""Here are the labels:"""

cvy = pd.read_excel('ex8data1.xlsx', sheet_name='y', header=None)
cvy.head()

y = np.array(cvy)
y

"""Here, the value of ‘y’ 0 suggests that that’s a normal example and the y value of 1indicates that, it is an anomalous example."""

p.describe()

"""Define a function to calculate the true positives, false positives, and false negatives:"""

def tpfpfn(ep):
    tp, fp, fn = 0, 0, 0
    for i in range(len(y)):
        if p[i] <= ep and y[i][0] == 1:
            tp += 1
        elif p[i] <= ep and y[i][0] == 0:
            fp += 1
        elif p[i] > ep and y[i][0] == 1:
            fn += 1
    return tp, fp, fn

"""Make a list of the probabilities that are lower than or equal to the mean probability."""

eps = [i for i in p if i <= p.mean()]

len(eps)

"""Define a function to calculate f1 score as per the formula we discussed before:"""

def f1(ep):
    tp, fp, fn = tpfpfn(ep)
    prec = tp/(tp + fp)
    rec = tp/(tp + fn)
    f1 = 2*prec*rec/(prec + rec)
    return f1

"""Now calculate the f1 score for all the epsilon or the range of probability values we selected before."""

f = []
for i in eps:
    f.append(f1(i))

f

"""This is part of the f score list. The length should be 133.

The f scores are usually ranged between 0 and 1 where 1 is the perfect f score. The higher the f1 score the better. So, we need to take the highest f score from the list of ‘f’ scores we just calculated.

**Now, use the ‘argmax’ function to determine the index of the maximum f score value.**
"""

np.array(f).argmax()

"""And now use this index to get the threshold probability."""

e = eps[131]
e

"""###Find out the Anomalous Examples
We have the threshold probability. We can find out the labels of our training data from it.

If the probability value is lower than or equal to this threshold value, the data is anomalous and otherwise, normal. We will denote the normal and anomalous data as 0and 1 respectively,
"""

label = []
for i in range(len(df)):
    if p[i] <= e:
        label.append(1)
    else:
        label.append(0)

label

"""This is part of the label list.

Adding this calculated labels in the training dataset above:
"""

df['label'] = np.array(label)

df.head()

import seaborn as sns

plt.figure(figsize=(16,6))
sns.lineplot(data=df)

plt.figure(figsize=(16,8))
sns.barplot(x=df['label'], y=df.index)

plt.figure(figsize=(20,10))
sns.heatmap(data=df.head(40), annot=True)

plt.figure(figsize=(20,10))
sns.swarmplot(x=df[0].head(80),
              y=df[1].head(80))

plt.figure(figsize=(16,8))
sns.kdeplot(data=df['label'],shade=True)

"""Source of this Algorithm is [here](https://towardsdatascience.com/a-complete-anomaly-detection-algorithm-from-scratch-in-python-step-by-step-guide-e1daf870336e)"""